{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "       NLP领域以及深度学习领域知识，从事NLP相关工作的能力。\n",
    "    2.2. what problems do you want to solve？\n",
    "       语言情感分析，句子生成，阅读理解。这个是能想到的。\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "        熟悉Python编程。\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "        数学基础不好。\n",
    "    2.5. How will you plan to study in this course period?\n",
    "        每周花一定时间完成作业，课程，课外补充数学，英语，深度学习知识，加强实践。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1. **智能音箱**\n",
    "2. **自动驾驶**\n",
    "3. **人脸识别**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: **We use github for sharing our code with other developer. Github provide us a good platform to communicate each other. \n",
    "We use Jupyter to programming in a interactive way. Because it is easy to run just a few line code in jupyter notebook, That is a good chioce if you want to make a demo fastly, for varify whether your idea is working. As for Pycharm, we should use it in formal and big projects. This IDE provide lots of good features for big projects. for instance, code automatic completion; Debug step by step; syntax check.**  \n",
    "1. **我们用github来和别的开发者分享代码，相互交流学习**\n",
    "2. **jupyter notebook 可以用来交互式写代码，可以很方便的一次仅仅运行几行代码，可以很方便快速的为我们的想法做出一个demo来验证想法的可行性.**\n",
    "3. **Pycharm更适合开发大型的正式的项目，pycharm 提供了很多对开发大型项目有用的工程。例如代码自动补全，单步调试，语法检查，代码搜索等等**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:  **概率模型是是用来描述不同随机变量之间关系的数学模型。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 例如天气预报，市场调查，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 因为基于规则的生成语言的方法，对规则过于依赖，有很大局限性。如果语法变了，那么代码就要变，适应性很差。使用概率的方法，可以从概率角度判断句子出现的概率从而判断合理性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:**一个用来判断句子出现概率的数学函数。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:**例如计算基于相邻单词的出现概率的句子出现的概率的语言模型，可以有效地判断句子的合理性。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: **仅仅计算句子中 长度为1的序列的概率的语言模型。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: **优点是容易计算，缺点是 没有考虑单词之间的关系，造成句子判断误差太大.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: **计算句子中长度为2的序列出现概率的语言模型.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "文章 = '一个 鸡蛋大小的东西 以20多马赫落下可以穿透足够厚度的钢板'\n",
    "hurt = '''\n",
    "hurt = 数量 大小描述的物品 以 速度 动作 导致 被伤害物品\n",
    "数量 = 一个 | 两个 | 200个 | 数量 或 数量\n",
    "大小描述的物品 = 物品 多少数量 的 结语 | 物品 | 形容词 物品\n",
    "物品 = 鸡蛋 | 石头 | 砖头 | 枕头 钢板 | 甲板\n",
    "多少数量 = 大小 | 多少 | 轻重 \n",
    "结语 = 东西 | 玩意儿 | 东东\n",
    "形容词 = 坚硬的 | 软软的 | 庞大的 | 足够厚度的\n",
    "速度 = 数字 多 单位 | 数字 单位 | 很大速度\n",
    "数字 = 1 | 2 | 3 | 4 | 数字 数字\n",
    "动作 = 落下 | 弹起 | 动作 再 动作 | 飞出 | 弹射\n",
    "导致 = 砸伤 | 穿透 | 刺穿\n",
    "被伤害物品 = 形容词 物品 \n",
    "单位 = 马赫 | km/s | 码 | 迈\n",
    "'''\n",
    "host =\"\"\"\n",
    "waiter = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def create_grammar(gram_text):\n",
    "    grammar = {}\n",
    "    for line in gram_text.strip().split(\"\\n\"):\n",
    "        #print(line,'&&&&')\n",
    "        key,value = line.strip().split(\"=\")\n",
    "        grammar[key.strip()] = [i.strip() for i in value.split(\"|\")]\n",
    "    return grammar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(grammar,key='host'):\n",
    "    value = random.choice(grammar.get(key))\n",
    "    ret = [generate(grammar,s) if s in grammar else s for s in value.split()]\n",
    "    return ''.join(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(grammar,root):\n",
    "    for i in range(16):\n",
    "        print(generate(grammar,root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar_host = create_grammar(host)\n",
    "grammar_human = create_grammar(human)\n",
    "grammar_hurt = create_grammar(hurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hurt': ['数量 大小描述的物品 以 速度 动作 导致 被伤害物品'],\n",
       " '动作': ['落下', '弹起', '动作 再 动作', '飞出', '弹射'],\n",
       " '单位': ['马赫', 'km/s', '码', '迈'],\n",
       " '多少数量': ['大小', '多少', '轻重'],\n",
       " '大小描述的物品': ['物品 多少数量 的 结语', '物品', '形容词 物品'],\n",
       " '导致': ['砸伤', '穿透', '刺穿'],\n",
       " '形容词': ['坚硬的', '软软的', '庞大的', '足够厚度的'],\n",
       " '数字': ['1', '2', '3', '4', '数字 数字'],\n",
       " '数量': ['一个', '两个', '200个', '数量 或 数量'],\n",
       " '物品': ['鸡蛋', '石头', '砖头', '枕头 钢板', '甲板'],\n",
       " '结语': ['东西', '玩意儿', '东东'],\n",
       " '被伤害物品': ['形容词 物品'],\n",
       " '速度': ['数字 多 单位', '数字 单位', '很大速度']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_hurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200个或两个或一个或两个枕头钢板以很大速度弹射刺穿庞大的砖头\n",
      "200个坚硬的鸡蛋以4码弹起再飞出砸伤软软的枕头钢板\n",
      "200个坚硬的石头以2迈弹射砸伤软软的枕头钢板\n",
      "两个足够厚度的鸡蛋以1马赫弹起再落下再弹起再落下再落下再弹射再弹起再落下再弹起再落下砸伤足够厚度的甲板\n",
      "一个足够厚度的甲板以很大速度弹射砸伤软软的砖头\n",
      "两个或一个或200个或200个庞大的枕头钢板以2km/s落下砸伤足够厚度的石头\n",
      "200个坚硬的甲板以4多km/s落下刺穿庞大的鸡蛋\n",
      "两个甲板以很大速度弹起穿透庞大的鸡蛋\n",
      "两个软软的甲板以12迈飞出刺穿庞大的枕头钢板\n",
      "两个甲板以3多迈弹起刺穿庞大的石头\n",
      "两个甲板以14多迈飞出穿透庞大的枕头钢板\n",
      "200个或两个庞大的石头以1迈落下再弹射穿透坚硬的甲板\n",
      "两个枕头钢板轻重的东东以344码飞出穿透软软的鸡蛋\n",
      "两个庞大的石头以1码弹起刺穿庞大的石头\n",
      "两个或一个坚硬的甲板以4码落下穿透坚硬的甲板\n",
      "一个鸡蛋大小的东东以2多km/s弹射再飞出穿透坚硬的石头\n"
     ]
    }
   ],
   "source": [
    "generate_n(grammar_hurt,'hurt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/xu/learningProject/AI_course/课程资料/2019-summer/assignments'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.txt') as f :\n",
    "    contents = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xu/environment/djangorestful/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3018: DtypeWarning: Columns (0,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_movie_comments = pd.read_csv('movie_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261497, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie_comments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_comments = df_movie_comments[pd.notna(df_movie_comments.comment)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = df_movie_comments.comment.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cont in contents:\n",
    "    try:\n",
    "        re.findall('\\\\w+',cont)\n",
    "    except:\n",
    "        print(cont,type(cont))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = ''.join([''.join(re.findall('\\\\w+', i)) for i in contents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'个坎父子情深还是蛮触动的赞当年比较经典文艺励志片威尔表演有激动人心一面当坚持不下去的时候再努力坚持一下好好好全年级一起看啊超级感动后面偷偷哭了当初看的时候挺难受的真的人穷到一定程度什么都能干的出来挺心酸的年轻的时候还会被励志踏入社会的我们只会发现迈过一个坎后还有无数个坎父子情深还是蛮触动的赞当年比较经典文艺励志片威尔表演有激动人心一面当坚持不下去的时候再努力坚持一下好好好全年级一起看啊超级感动后面偷偷哭了上高中的时候老师推荐看的很励志温馨父子多令人羡慕好看对教堂唱歌那段印象深刻MIT带着我哭带着我笑励志我人生的这部分这个小阶段叫作幸福典型美国人电影美国人美国Thisispartofmylife很好的励志片or揭示了资本主义社会中金钱对人的异化的政治讽喻片总算看了这部电影可能以前看过太多关于这部电影的文字对这个故事的大概已经知晓所以没感觉特别新鲜总之是部不错的电影或许以后会和儿子一起重看一遍温馨父子多令人羡慕好看对教堂唱歌那段印象深刻MIT带着我哭带着我笑励志我人生的这部分这个小阶段叫作幸福典型美国人电影美国人美国Thisispartofmylife很好的励志片or揭示了资本主义社会中金钱对人的异化的政治讽喻片总算看了这部电影可能以前看过太多关于这部电影的文字对这个故事的大概已经知晓所以没感觉特别新鲜总之是部不错的电影或许以后会和儿子一起重看一遍一个励志的好故事也许我们正处于窘迫的环境面临着艰苦的奋斗但只要不放弃希望总会迎来一道曙光学会承担每时每刻本片深刻地教育了学BME的千万别卖医疗器材不努力毋宁死有什么坚持不下来的呢只要有梦想拍得很传统细节非常用心整体反而略弱也许改编传记很容易这样总之我蛮喜欢这故事我妈喜欢看煽情美国宣传美国梦的又一伎俩一个励志的好故事也许我们正处于窘迫的环境面临着艰苦的奋斗但只要不放弃希望总会迎来一道曙光学会承担每时每刻本片深刻地教育了学BME的千万别卖医疗器材不努力毋宁死有什么坚持不下来的呢只要有梦想拍得很传统细节非常用心整体反而略弱也许改编传记很容易这样总之我蛮喜欢这故事我妈喜欢看煽情美国宣传美国梦的又一伎俩励志感动就好了這爸爸好牛和囡囡一起看的那个无敌的强大的时光机1011好又哭了感动看了一半实在懒得看完真励志平民励志那个小不点很可爱虎父无犬子thepursuitofhappyness无论怎样撂倒无论怎样艰难也要奋斗也要努力老一套温情稍稍让'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[10000:11000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutted_words = [i for i in jieba.cut(articles) if i != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "token = Counter(cutted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题 \n",
    "1. 大小写，单复数\n",
    "2. 前后两句话被生硬的连接在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'吴京'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_words = copy.copy(cutted_words)\n",
    "first_words.pop(-1)\n",
    "\n",
    "last_words = copy.copy(cutted_words)\n",
    "last_words.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2_gram = [x+y for x,y in zip(first_words,last_words)]\n",
    "word_count_2 = Counter(token_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(token1, token2):\n",
    "    token12 = token1+token2\n",
    "    count = word_count_2[token12] if token12 in token_2_gram else 1\n",
    "    return count/len(token_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.685935532872405e-07"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('飞机','大炮')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_probility(sentence):\n",
    "    words = list(jieba.cut(sentence))\n",
    "    first_word,last_words = copy.copy(words),copy.copy(words)\n",
    "    first_word.pop(-1)\n",
    "    last_words.pop(0)\n",
    "    word_2 = [prob_2(x,y) for x,y in zip(first_word,last_words)]\n",
    "    return np.prod(word_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(): # you code here\n",
    "    all_sentence = []\n",
    "    for i in range(30):\n",
    "        sen = generate(grammar_hurt, 'hurt')\n",
    "        prob = get_probility(sen)\n",
    "        all_sentence.append((prob,sen))\n",
    "        print((prob,sen))\n",
    "    print(\"Best: \",max(all_sentence,key=lambda x:x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.720519288900412e-66, '一个石头以很大速度飞出刺穿软软的砖头')\n",
      "(3.972656362279101e-76, '200个坚硬的鸡蛋以很大速度弹射砸伤软软的石头')\n",
      "(3.360770017575745e-83, '200个石头多少的玩意儿以很大速度弹起刺穿软软的鸡蛋')\n",
      "(1.3551492006353813e-84, '两个甲板大小的东东以很大速度飞出砸伤软软的砖头')\n",
      "(3.38068513626174e-87, '一个石头大小的东西以很大速度飞出砸伤足够厚度的石头')\n",
      "(3.0114426680786257e-85, '一个足够厚度的砖头以234km/s弹起穿透坚硬的甲板')\n",
      "(9.90301791660753e-71, '200个枕头钢板以很大速度弹起刺穿坚硬的石头')\n",
      "(6.488672058389198e-74, '两个坚硬的石头以1多马赫落下穿透坚硬的石头')\n",
      "(1.6225770359178895e-117, '两个或一个或200个软软的石头以2km/s飞出穿透软软的枕头钢板')\n",
      "(6.155665565133904e-79, '两个石头以4多km/s飞出砸伤庞大的砖头')\n",
      "(1.6635608143803795e-156, '一个或200个或一个或200个或一个坚硬的砖头以1多km/s弹射刺穿庞大的鸡蛋')\n",
      "(2.720519288900412e-66, '一个甲板以很大速度飞出砸伤软软的砖头')\n",
      "(6.899357420942328e-89, '一个砖头多少的东西以4km/s弹起穿透足够厚度的砖头')\n",
      "(1.0038142226928748e-85, '一个鸡蛋以2多km/s飞出刺穿坚硬的枕头钢板')\n",
      "(8.286198664916507e-72, '两个庞大的砖头以4132多迈弹起穿透软软的甲板')\n",
      "(4.026862307942992e-91, '200个鸡蛋轻重的东东以224多码飞出刺穿足够厚度的甲板')\n",
      "(1.2126144387682688e-72, '200个枕头钢板以很大速度弹起砸伤软软的鸡蛋')\n",
      "(2.0210240646137814e-73, '200个枕头钢板以4多迈落下刺穿软软的甲板')\n",
      "(3.0371674194303306e-105, '200个足够厚度的甲板以3km/s弹起再弹射穿透庞大的砖头')\n",
      "(3.5124841205711775e-101, '一个或200个枕头钢板轻重的东西以12多码弹射砸伤庞大的甲板')\n",
      "(5.44977161339039e-57, '一个砖头以2码弹起刺穿庞大的石头')\n",
      "(8.948582906539978e-93, '两个枕头钢板以4km/s弹射再弹射刺穿足够厚度的鸡蛋')\n",
      "(9.233498347700858e-77, '一个庞大的枕头钢板以很大速度落下砸伤坚硬的砖头')\n",
      "(1.3512436606391496e-79, '200个软软的砖头以很大速度弹起穿透软软的砖头')\n",
      "(4.517164002117939e-84, '两个坚硬的甲板以2多马赫飞出穿透坚硬的砖头')\n",
      "(2.104383074134325e-116, '两个枕头钢板轻重的玩意儿以很大速度飞出再飞出再落下砸伤庞大的枕头钢板')\n",
      "(8.084096258455125e-73, '200个鸡蛋以2多马赫弹射穿透软软的甲板')\n",
      "(2.7437588753605244e-85, '两个足够厚度的枕头钢板以32迈弹起刺穿庞大的砖头')\n",
      "(3.68994743512456e-125, '200个或200个或一个足够厚度的甲板以441马赫落下砸伤坚硬的枕头钢板')\n",
      "(1.125297827551612e-80, '一个鸡蛋轻重的玩意儿以很大速度飞出穿透庞大的石头')\n",
      "Best:  (5.44977161339039e-57, '一个砖头以2码弹起刺穿庞大的石头')\n"
     ]
    }
   ],
   "source": [
    "generate_best()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "1. **这个语料库，不够大，导致 对概率的估计不是特别准确.** \n",
    "2. **分词的方案并不完美， 要采取更多的技巧提升分词准确度。**\n",
    "3. **如果一个句子较长，那么他有较大的可能会得到一个较小的概率，我决定应该采取 类似 pagerank 算法中的逆文档频率来处理他们。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
